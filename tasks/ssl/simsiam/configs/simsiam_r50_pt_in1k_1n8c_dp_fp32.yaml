# global configs
Global:
  task_type: ContrastiveLearning
  train_loop: ContrastiveLearningTrainingEpochLoop
  validate_loop: None
  checkpoint: null
  pretrained_model: null
  output_dir: ./output/
  device: gpu
  save_interval: 1
  max_num_latest_checkpoint: 0
  eval_during_train: False
  eval_interval: 1
  eval_unit: "epoch"
  accum_steps: 1
  epochs: 100
  print_batch_step: 50
  use_visualdl: False
  seed: 2023


DistributedStrategy:
  data_parallel: True

# model architecture
Model:
  name: SimSiam

LRScheduler:
    name: TimmCosine
    learning_rate: 0.1
    eta_min: 0.0
    warmup_epoch: 0
    warmup_start_lr: 0.0
    decay_unit: epoch
    warmup_prefix: False
    last_epoch: 0

Optimizer:
  name: Momentum
  weight_decay: 0.0001
  use_master_param: True
  exp_avg_force_fp32: True
  tensor_fusion: False

# data loader for train and eval
DataLoader:
  Train:
    dataset:
      name: ImageFolder
      root: ./dataset/ILSVRC2012/train
      transform:
        - TwoViewsTransform:
            base_transform1:
              - RandomResizedCrop:
                  size: 224
                  scale: [0.2, 1.]
              - ColorJitter:
                  p: 0.8
                  brightness: 0.4
                  contrast: 0.4
                  saturation: 0.4
                  hue: 0.1
              - RandomGrayscale:
                  p: 0.2
              - SimCLRGaussianBlur:
                  p: 0.5
                  sigma: [.1, 2.]
              - RandomHorizontalFlip:
              - ToTensor:
              - Normalize:
                  mean: [0.485, 0.456, 0.406]
                  std: [0.229, 0.224, 0.225]

            base_transform2:
              - RandomResizedCrop:
                  size: 224
                  scale: [0.2, 1.0]
              - ColorJitter:
                  p: 0.8
                  brightness: 0.4
                  contrast: 0.4
                  saturation: 0.4
                  hue: 0.1
              - RandomGrayscale:
                  p: 0.2
              - SimCLRGaussianBlur:
                  p: 0.5
                  sigma: [ .1, 2. ]
              - RandomHorizontalFlip:
              - ToTensor:
              - Normalize:
                  mean: [0.485, 0.456, 0.406]
                  std: [0.229, 0.224, 0.225]
    sampler:
      name: DistributedBatchSampler
      batch_size: 64
      drop_last: False
      shuffle: True
    loader:
      num_workers: 8
      use_shared_memory: True
